{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrayping Data NoteBook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "import csv\n",
    "import re\n",
    "import sys, getopt\n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input for Scrayping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = 'Juventus'\n",
    "pk = 'e0652b02'\n",
    "url = f'https://fbref.com/en/squads/{pk}/{team}-Stats'\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.content,'html.parser')\n",
    "table = soup.table\n",
    "tbody = table.find('tbody')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minutes = tbody.find_all(attrs={\"data-stat\": \"minutes\"})\n",
    "\n",
    "min_list = []\n",
    "for minute in minutes:\n",
    "    min_list.append(minute.text)\n",
    "\n",
    "\n",
    "names = tbody.find_all(attrs={'data-stat': 'player'})\n",
    "\n",
    "name_list = []\n",
    "for name in names:\n",
    "    name_list.append(name.a.text)\n",
    "\n",
    "\n",
    "ages = tbody.find_all(attrs={'data-stat':'age'})\n",
    "age_list = []\n",
    "for age in ages:\n",
    "    age_list.append(age.text[:2])\n",
    "\n",
    "\n",
    "xgs = tbody.find_all(attrs={'data-stat':'xg'})\n",
    "xg_list =[]\n",
    "for xg in xgs:\n",
    "    xg_list.append(xg.text)\n",
    "\n",
    "\n",
    "xas = tbody.find_all(attrs={'data-stat':'xa'})\n",
    "xa_list = []\n",
    "for xa in xas:\n",
    "    xa_list.append(xa.text)\n",
    "\n",
    "\n",
    "npxgs = tbody.find_all(attrs={'data-stat':'npxg'})\n",
    "npxg_list = []\n",
    "for npxg in npxgs:\n",
    "    npxg_list.append(npxg.text)\n",
    "\n",
    "\n",
    "\n",
    "npxg_xas= tbody.find_all(attrs={'data-stat':'npxg_xa_per90'})\n",
    "npxg_xa_list = []\n",
    "for npxg_xa in npxg_xas:\n",
    "    npxg_xa_list.append(npxg_xa.text)\n",
    "\n",
    "\n",
    "with open(f'../assets/{team}/{team}_month12.csv', 'w') as csv_file:\n",
    "    fieldnames = ['team', 'name', 'age', 'mplay',  'xG', 'xA', 'npxG', 'npxG + xA']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for name, age, minute, xg, xa, npxg, npxg_xa in zip(name_list, age_list, min_list, xg_list, xa_list, npxg_list, npxg_xa_list):\n",
    "        writer.writerow({'team':team,'name': name, 'age':age,  'mplay': minute, 'xG':xg, 'xA':xa, 'npxG':npxg, 'npxG + xA':npxg_xa})      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code of Comment Escape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = requests.get(url)\n",
    "## The next two lines get around the issue with comments breaking the parsing.\n",
    "comm = re.compile('<!--|-->')\n",
    "soup = BeautifulSoup(comm.sub(\"\",html.text),'lxml')\n",
    "# soup = BeautifulSoup(html.content,'html.parser')\n",
    "\n",
    "tbody = soup.findAll(\"tbody\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Basic Pass Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody_pass = tbody[5]\n",
    "\n",
    "players = tbody_pass.find_all(attrs={'data-stat':'player'})\n",
    "player_list = []\n",
    "for pass_player in players:\n",
    "    player_list.append(pass_player.text)\n",
    "\n",
    "positions = tbody_pass.find_all(attrs={'data-stat':'position'})\n",
    "position_list = []\n",
    "for position in positions:\n",
    "    position_list.append(position.text)\n",
    "\n",
    "minute90s = tbody_pass.find_all(attrs={'data-stat':'minutes_90s'})\n",
    "minute90_list = []\n",
    "for minute90 in minute90s:\n",
    "    minute90_list.append(minute90.text)\n",
    "\n",
    "pass_attempts = tbody_pass.find_all(attrs={'data-stat':'passes'})\n",
    "attempt_list = []\n",
    "for pass_attempt in pass_attempts:\n",
    "    attempt_list.append(pass_attempt.text)\n",
    "\n",
    "pass_comps = tbody_pass.find_all(attrs={'data-stat':'passes_completed'})\n",
    "comp_list = []\n",
    "for pass_comp in pass_comps:\n",
    "    comp_list.append(pass_comp.text)\n",
    "\n",
    "\n",
    "pass_pct = tbody_pass.find_all(attrs={'data-stat':'passes_pct'})\n",
    "pct_list = []\n",
    "for pct in pass_pct:\n",
    "    pct_list.append(pct.text)\n",
    "\n",
    "pass_distances = tbody_pass.find_all(attrs={'data-stat':'passes_total_distance'})\n",
    "distance_list = []\n",
    "for pass_distance in pass_distances:\n",
    "    distance_list.append(pass_distance.text)\n",
    "\n",
    "\n",
    "pass_progress = tbody_pass.find_all(attrs={'data-stat':'passes_progressive_distance'})\n",
    "progres_list = []\n",
    "for pass_progres in pass_progress:\n",
    "    progres_list.append(pass_progres.text)\n",
    "\n",
    "pass_longs = tbody_pass.find_all(attrs={'data-stat':'passes_long'})\n",
    "long_list = []\n",
    "for pass_long in pass_longs:\n",
    "    long_list.append(pass_long.text)\n",
    "\n",
    "\n",
    "pass_comp_longs = tbody_pass.find_all(attrs={'data-stat':'passes_completed_long'})\n",
    "comp_long_list = []\n",
    "for pass_comp_long in pass_comp_longs:\n",
    "    comp_long_list.append(pass_comp_long.text)\n",
    "\n",
    "long_comp_pcts = tbody_pass.find_all(attrs={'data-stat':'passes_pct_long'})\n",
    "long_comp_pct_list = []\n",
    "for long_comp_pct in long_comp_pcts:\n",
    "    long_comp_pct_list.append(long_comp_pct.text)\n",
    "\n",
    "\n",
    "pass_mediums = tbody_pass.find_all(attrs={'data-stat':'passes_medium'})\n",
    "medium_list = []\n",
    "for pass_medium in pass_mediums:\n",
    "    medium_list.append(pass_medium.text)\n",
    "\n",
    "\n",
    "pass_comp_mediums = tbody_pass.find_all(attrs={'data-stat':'passes_completed_medium'})\n",
    "comp_medium_list = []\n",
    "for pass_comp_medium in pass_comp_mediums:\n",
    "    comp_medium_list.append(pass_comp_medium.text)\n",
    "\n",
    "\n",
    "medium_comp_pcts = tbody_pass.find_all(attrs={'data-stat':'passes_pct_medium'})\n",
    "medium_comp_pct_list = []\n",
    "for medium_comp_pct in medium_comp_pcts:\n",
    "    medium_comp_pct_list.append(medium_comp_pct.text)\n",
    "\n",
    "pass_shorts = tbody_pass.find_all(attrs={'data-stat':'passes_short'})\n",
    "short_list = []\n",
    "for pass_short in pass_shorts:\n",
    "    short_list.append(pass_short.text)\n",
    "\n",
    "\n",
    "pass_comp_shorts = tbody_pass.find_all(attrs={'data-stat':'passes_completed_short'})\n",
    "comp_short_list = []\n",
    "for pass_comp_short in pass_comp_shorts:\n",
    "    comp_short_list.append(pass_comp_short.text)\n",
    "\n",
    "\n",
    "short_comp_pcts = tbody_pass.find_all(attrs={'data-stat':'passes_pct_short'})\n",
    "short_comp_pct_list = []\n",
    "for short_comp_pct in short_comp_pcts:\n",
    "    short_comp_pct_list.append(short_comp_pct.text)\n",
    "\n",
    "keypasses = tbody_pass.find_all(attrs={'data-stat':'assisted_shots'})\n",
    "keypass_list = []\n",
    "for keypass in keypasses:\n",
    "    keypass_list.append(keypass.text)\n",
    "\n",
    "\n",
    "pass_final_thirds = tbody_pass.find_all(attrs={'data-stat':'passes_into_final_third'})\n",
    "final_third_list = []\n",
    "for pass_final_third in pass_final_thirds:\n",
    "    final_third_list.append(pass_final_third.text)\n",
    "\n",
    "\n",
    "pass_into_penaltys = tbody_pass.find_all(attrs={'data-stat':'passes_into_penalty_area'})\n",
    "into_penalty_list = []\n",
    "for pass_into_penalty in pass_into_penaltys:\n",
    "    into_penalty_list.append(pass_into_penalty.text)\n",
    "\n",
    "\n",
    "\n",
    "cross_into_penaltys = tbody_pass.find_all(attrs={'data-stat':'crosses_into_penalty_area'})\n",
    "cross_list = []\n",
    "for cross_into_penalty in cross_into_penaltys:\n",
    "    cross_list.append(cross_into_penalty.text)\n",
    "\n",
    "progressive_passes = tbody_pass.find_all(attrs={'data-stat':'progressive_passes'})\n",
    "progressive_pass_list = []\n",
    "for progressive_pass in progressive_passes:\n",
    "    progressive_pass_list.append(progressive_pass.text)\n",
    "\n",
    "\n",
    "with open(f'../assets/{team}/{team}_pass.csv', 'w') as csv_file:\n",
    "\n",
    "    fieldnames = ['Player', 'Position','Minute90','Attempt', 'Completed', 'Sucpct', 'Totaldist', 'Progdist', 'LongPass', 'LongComp', 'LongPct', 'MediPass', 'MediComp', 'MediPct', 'ShortPass', 'ShortComp', 'ShortPct', 'Keypass', 'Finalthird', 'Penalty', 'CrossPena','Progcount']\n",
    "\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for player, position, minute90, attempt, comp, pct, distance, progres, long, complong, pctlong, medium, compmedium, pctmedium,short, compshort, pctshort, keypass, final, penalty, cross, pxxxx in zip(player_list, position_list, minute90_list, attempt_list, comp_list, pct_list, distance_list, progres_list, long_list, comp_long_list, long_comp_pct_list, medium_list, comp_medium_list, medium_comp_pct_list, short_list, comp_short_list, short_comp_pct_list, keypass_list,final_third_list, into_penalty_list, cross_list, progressive_pass_list):\n",
    "        writer.writerow({'Player':player, 'Position':position, 'Minute90':minute90,'Attempt':attempt,'Completed': comp, 'Sucpct':pct, 'Totaldist':distance, 'Progdist':progres, 'LongPass':long, 'LongComp':complong,'LongPct':pctlong, 'MediPass':medium, 'MediComp':compmedium, 'MediPct':pctmedium, 'ShortPass':short, 'ShortComp':compshort, 'ShortPct':pctshort, 'Keypass':keypass, 'Finalthird':final, 'Penalty':penalty, 'CrossPena':cross,'Progcount':pxxxx})      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pass Type Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody_ptype = tbody[6]\n",
    "\n",
    "players = tbody_ptype.find_all(attrs={'data-stat':'player'})\n",
    "player_list = []\n",
    "for pass_player in players:\n",
    "    player_list.append(pass_player.text)\n",
    "\n",
    "\n",
    "pass_presses = tbody_ptype.find_all(attrs={'data-stat':'passes_pressure'})\n",
    "press_list = []\n",
    "for pass_press in pass_presses:\n",
    "    press_list.append(pass_press.text)\n",
    "\n",
    "\n",
    "pass_switches = tbody_ptype.find_all(attrs={'data-stat':'passes_switches'})\n",
    "switch_list = []\n",
    "for pass_switch in pass_switches:\n",
    "    switch_list.append(pass_switch.text)\n",
    "\n",
    "pass_intercepts = tbody_ptype.find_all(attrs={'data-stat':'passes_intercepted'})\n",
    "intercept_list = []\n",
    "for pass_intercept in pass_intercepts:\n",
    "    intercept_list.append(pass_intercept.text)\n",
    "\n",
    "pass_blockes = tbody_ptype.find_all(attrs={'data-stat':'passes_blocked'})\n",
    "block_list = []\n",
    "for pass_block in pass_blockes:\n",
    "    block_list.append(pass_block.text)\n",
    "\n",
    "with open(f'../assets/{team}/{team}_ptype.csv', 'w') as csv_file:\n",
    "    fieldnames = ['player', 'press', 'switch', 'intercepted', 'blocked']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for player, press, switch, intercept, block in zip(player_list, press_list,switch_list, intercept_list, block_list):\n",
    "        writer.writerow({'player':player,'press':press, 'switch':switch, 'intercepted':intercept, 'blocked':block})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Shoot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody_shoot = tbody[4]\n",
    "\n",
    "goals = tbody_shoot.find_all(attrs={'data-stat':'goals'})\n",
    "goal_list = []\n",
    "for goal in goals:\n",
    "    goal_list.append(goal.text)\n",
    "\n",
    "\n",
    "xgs = tbody_shoot.find_all(attrs={'data-stat':'xg'})\n",
    "xg_list = []\n",
    "for xg in xgs:\n",
    "    xg_list.append(xg.text)\n",
    "\n",
    "shoots_total = tbody_shoot.find_all(attrs={'data-stat':'shots_total'})\n",
    "shoot_total_list = []\n",
    "for shoot in shoots_total:\n",
    "    shoot_total_list.append(shoot.text)\n",
    "\n",
    "\n",
    "shoot90s = tbody_shoot.find_all(attrs={'data-stat':'shots_total_per90'})\n",
    "shoot90_list = []\n",
    "for shoot90 in shoot90s:\n",
    "    shoot90_list.append(shoot90.text)\n",
    "\n",
    "\n",
    "sots = tbody_shoot.find_all(attrs={'data-stat':'shots_on_target'})\n",
    "sot_list = []\n",
    "for sot in sots:\n",
    "    sot_list.append(sot.text)\n",
    "\n",
    "\n",
    "sot90s = tbody_shoot.find_all(attrs={'data-stat':'shots_on_target_per90'})\n",
    "sot90_list = []\n",
    "for sot in sot90s:\n",
    "    sot90_list.append(sot.text)\n",
    "\n",
    "players = tbody_shoot.find_all(attrs={'data-stat':'player'})\n",
    "player_list = []\n",
    "for player in players:\n",
    "    player_list.append(player.text)\n",
    "\n",
    "\n",
    "with open(f'../assets/{team}/{team}_shoot.csv', 'w') as csv_file:\n",
    "    fieldnames = ['Player', 'Gls', 'xG', 'TotalS', 'TotalS/90', 'SonTar', 'SonT/90']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for player, gl, xg, ts, ts90, sot, sot90 in zip(player_list, goal_list, xg_list, shoot_total_list ,shoot90_list, sot_list, sot90_list):\n",
    "        writer.writerow({'Player':player, 'Gls':gl, 'xG':xg, 'TotalS':ts, 'TotalS/90':ts90, 'SonTar':sot, 'SonT/90':sot90})      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Attack Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody_attack = tbody[7]\n",
    "\n",
    "players = tbody_attack.find_all(attrs={'data-stat':'player'})\n",
    "player_list = []\n",
    "for player in players:\n",
    "    player_list.append(player.text)\n",
    "    \n",
    "scas = tbody_attack.find_all(attrs={'data-stat':'sca'})\n",
    "sca_list = []\n",
    "for sca in scas:\n",
    "    sca_list.append(sca.text)\n",
    "\n",
    "sca_per90s = tbody_attack.find_all(attrs={'data-stat': 'sca_per90'})\n",
    "sca_per90_list = []\n",
    "for sca_per90 in sca_per90s:\n",
    "    sca_per90_list.append(sca_per90.text)\n",
    "\n",
    "sca_passes_lives = tbody_attack.find_all(attrs={'data-stat': 'sca_passes_live'})\n",
    "sca_passes_live_list = []\n",
    "for sca_passes_live in sca_passes_lives:\n",
    "    sca_passes_live_list.append(sca_passes_live.text)\n",
    "\n",
    "sca_passes_deads = tbody_attack.find_all(attrs={'data-stat': 'sca_passes_dead'})\n",
    "sca_passes_dead_list = []\n",
    "for sca_passes_dead in sca_passes_deads:\n",
    "    sca_passes_dead_list.append(sca_passes_dead.text)\n",
    "\n",
    "sca_dribbles = tbody_attack.find_all(attrs={'data-stat': 'sca_dribbles'})\n",
    "sca_dribble_list = []\n",
    "for sca_dribble in sca_dribbles:\n",
    "    sca_dribble_list.append(sca_dribble.text)\n",
    "\n",
    "sca_shots = tbody_attack.find_all(attrs={'data-stat': 'sca_shots'})\n",
    "sca_shot_list = []\n",
    "for sca_shot in sca_shots:\n",
    "    sca_shot_list.append(sca_shot.text)\n",
    "\n",
    "sca_fouleds = tbody_attack.find_all(attrs={'data-stat': 'sca_fouled'})\n",
    "sca_fouled_list = []\n",
    "for sca_fouled in sca_fouleds:\n",
    "    sca_fouled_list.append(sca_fouled.text)\n",
    "\n",
    "\n",
    "sca_defenses = tbody_attack.find_all(attrs={'data-stat': 'sca_defense'})\n",
    "sca_defense_list = []\n",
    "for sca_defense in sca_defenses:\n",
    "    sca_defense_list.append(sca_defense.text)\n",
    "\n",
    "\n",
    "gcas = tbody_attack.find_all(attrs={'data-stat': 'gca'})\n",
    "gca_list = []\n",
    "for gca in gcas:\n",
    "    gca_list.append(gca.text)\n",
    "\n",
    "\n",
    "gca_per90s = tbody_attack.find_all(attrs={'data-stat': 'gca_per90'})\n",
    "gca_per90_list = []\n",
    "for gca_per90 in gca_per90s:\n",
    "    gca_per90_list.append(gca_per90.text)\n",
    "\n",
    "\n",
    "gca_passes_lives = tbody_attack.find_all(attrs={'data-stat': 'gca_passes_live'})\n",
    "gca_passes_live_list = []\n",
    "for gca_passes_live in gca_passes_lives:\n",
    "    gca_passes_live_list.append(gca_passes_live.text)\n",
    "\n",
    "gca_passes_deads = tbody_attack.find_all(attrs={'data-stat': 'gca_passes_dead'})\n",
    "gca_passes_dead_list = []\n",
    "for gca_passes_dead in gca_passes_deads:\n",
    "    gca_passes_dead_list.append(gca_passes_dead.text)\n",
    "\n",
    "gca_dribbles = tbody_attack.find_all(attrs={'data-stat': 'gca_dribbles'})\n",
    "gca_dribble_list = []\n",
    "for gca_dribble in gca_dribbles:\n",
    "    gca_dribble_list.append(gca_dribble.text)\n",
    "\n",
    "gca_shots = tbody_attack.find_all(attrs={'data-stat': 'gca_shots'})\n",
    "gca_shot_list = []\n",
    "for gca_shot in gca_shots:\n",
    "    gca_shot_list.append(gca_shot.text)\n",
    "\n",
    "gca_fouleds = tbody_attack.find_all(attrs={'data-stat': 'gca_fouled'})\n",
    "gca_fouled_list = []\n",
    "for gca_fouled in gca_fouleds:\n",
    "    gca_fouled_list.append(gca_fouled.text)\n",
    "\n",
    "gca_defenses = tbody_attack.find_all(attrs={'data-stat': 'gca_defense'})\n",
    "gca_defense_list = []\n",
    "for gca_defense in gca_defenses:\n",
    "    gca_defense_list.append(gca_defense.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "with open(f'../assets/{team}/{team}_attack.csv', 'w') as csv_file:\n",
    "    fieldnames = ['player', 'sca', 'sca90', 's_passlive', 's_passdead', 's_drib', 's_sh', 's_fld', 's_def','gca', 'gca90','g_passlive', 'g_passdead', 'g_drib', 'g_sh', 'g_fld', 'g_def']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for player, sca, sca90, s_passlive, s_passdead, s_drib, s_sh, s_fld, s_def ,gca ,gca90, g_passlive, g_passdead, g_drib, g_sh, g_fld, g_def in zip(player_list,sca_list, sca_per90_list, sca_passes_live_list ,sca_passes_dead_list,sca_dribble_list,sca_shot_list,sca_fouled_list,sca_defense_list,gca_list,gca_per90_list, gca_passes_live_list,gca_passes_dead_list,gca_dribble_list,gca_shot_list,gca_fouled_list,gca_defense_list):\n",
    "        writer.writerow({'player':player, 'sca':sca, 'sca90':sca90, 's_passlive':s_passlive, 's_passdead':s_passdead, 's_drib':s_drib, 's_sh':s_sh, 's_fld':s_fld, 's_def':s_def,'gca':gca, 'gca90':gca90,'g_passlive':g_passlive, 'g_passdead':g_passdead, 'g_drib':g_drib, 'g_sh':g_sh, 'g_fld':g_fld, 'g_def':g_def})\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = 'barcelona'\n",
    "player_pk_dict = {\n",
    "                  'Lionel-Messi':'d70ce98e',\n",
    "                  'Francisco-Trincao':'b19db005', \n",
    "                  'Ansu-Fati':'0ba976e4',\n",
    "                  'Pedri':'0d9b2d31',\n",
    "                  'Philippe-Coutinho':'0ef89a37',\n",
    "                  'Antoine-Griezmann':'df69b544',\n",
    "                  'Ousmane-Dembele':'b19db005'\n",
    "                 } \n",
    "\n",
    "for key, value in player_pk_dict.items():\n",
    "    \n",
    "\n",
    "    pk = value\n",
    "    player = key\n",
    "\n",
    "\n",
    "    url = f'https://fbref.com/en/players/{pk}/matchlogs/2020-2021/summary/{player}-Match-Logs'\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "    table = soup.table\n",
    "\n",
    "\n",
    "    opponents = table.find_all(attrs={'data-stat':'opponent'})\n",
    "    opponent_list = []\n",
    "    for opponent in opponents[1:-1]:\n",
    "        opponent_list.append(opponent.text)\n",
    "    opponent_list\n",
    "\n",
    "    start_or_no = table.find_all(attrs={'data-stat':'game_started'})\n",
    "    start_or_no_list = []\n",
    "    for son in start_or_no[1:-1]:\n",
    "        start_or_no_list.append(son.text)\n",
    "    start_or_no_list\n",
    "\n",
    "    position = table.find_all(attrs={'data-stat':'position'})\n",
    "    position_list = []\n",
    "    for position in position[1:-1]:\n",
    "        position_list.append(position.text)\n",
    "    position_list\n",
    "\n",
    "    minute = table.find_all(attrs={'data-stat': 'minutes'})\n",
    "    minute_list = []\n",
    "    for minute in minute[1:-1]:\n",
    "        minute_list.append(minute.text)\n",
    "    minute_list\n",
    "\n",
    "    shots_on_target = table.find_all(attrs={'data-stat': 'shots_on_target'})\n",
    "    shots_on_target_list = []\n",
    "    for shots_on_target in shots_on_target[1:-1]:\n",
    "        shots_on_target_list.append(shots_on_target.text)\n",
    "    shots_on_target_list\n",
    "\n",
    "    touches = table.find_all(attrs={'data-stat': 'touches'})\n",
    "    touches_list = []\n",
    "    for touches in touches[1:-1]:\n",
    "        touches_list.append(touches.text)\n",
    "    touches_list\n",
    "\n",
    "    pressures = table.find_all(attrs={'data-stat': 'pressures'})\n",
    "    pressures_list = []\n",
    "    for pressures in pressures[1:-1]:\n",
    "        pressures_list.append(pressures.text)\n",
    "    pressures_list\n",
    "\n",
    "    xg = table.find_all(attrs={'data-stat': 'xg'})\n",
    "    xg_list = []\n",
    "    for xg in xg[1:-1]:\n",
    "        xg_list.append(xg.text)\n",
    "    xg_list\n",
    "\n",
    "    xa = table.find_all(attrs={'data-stat': 'xa'})\n",
    "    xa_list = []\n",
    "    for xa in xa[1:-1]:\n",
    "        xa_list.append(xa.text)\n",
    "    xa_list\n",
    "\n",
    "    sca = table.find_all(attrs={'data-stat': 'sca'})\n",
    "    sca_list = []\n",
    "    for sca in sca[1:-1]:\n",
    "        sca_list.append(sca.text)\n",
    "    sca_list\n",
    "\n",
    "    gca = table.find_all(attrs={'data-stat': 'gca'})\n",
    "    gca_list = []\n",
    "    for gca in gca[1:-1]:\n",
    "        gca_list.append(gca.text)\n",
    "    gca_list\n",
    "\n",
    "    passes_pct = table.find_all(attrs={'data-stat': 'passes_pct'})\n",
    "    passes_pct_list = []\n",
    "    for passes_pct in passes_pct[1:-1]:\n",
    "        passes_pct_list.append(passes_pct.text)\n",
    "    passes_pct_list\n",
    "\n",
    "    carries = table.find_all(attrs={'data-stat': 'carries'})\n",
    "    carries_list = []\n",
    "    for carries in carries[1:-1]:\n",
    "        carries_list.append(carries.text)\n",
    "    carries_list\n",
    "\n",
    "    carry_progressive_distance = table.find_all(attrs={'data-stat': 'carry_progressive_distance'})\n",
    "    carry_progressive_distance_list = []\n",
    "    for carry_progressive_distance in carry_progressive_distance[1:-1]:\n",
    "        carry_progressive_distance_list.append(carry_progressive_distance.text)\n",
    "    # carry_progressive_distance_list\n",
    "\n",
    "\n",
    "    dribbles = table.find_all(attrs={'data-stat': 'dribbles'})\n",
    "    dribbles_list = []\n",
    "    for dribbles in dribbles[1:-1]:\n",
    "        dribbles_list.append(dribbles.text)\n",
    "    dribbles_list\n",
    "\n",
    "\n",
    "    dribbles_completed = table.find_all(attrs={'data-stat': 'dribbles_completed'})\n",
    "    dribbles_completed_list = []\n",
    "    for dribbles_completed in dribbles_completed[1:-1]:\n",
    "        dribbles_completed_list.append(dribbles_completed.text)\n",
    "    dribbles_completed_list\n",
    "\n",
    "    player_list = [ player for i in range(len(opponent_list))]\n",
    "\n",
    "    \n",
    "    \n",
    "    with open(f'../assets/{team}/player/{player}_basic.csv', 'w') as csv_file:\n",
    "        fieldnames = ['player', 'opponent', 'start', 'position', 'minute', \n",
    "                'touch', 'pressure', 'xg', 'xa', 'sca', 'gca', 'sot', 'pass_pct',\n",
    "                'carries', 'prog_dis', 'dribble_attempt', 'dribble_suc']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for player, opponent, start, position, minute, touch, pressure, xg, xa, sca, gca, sot, pass_pct, carry, prog_dis, dribble, dribble_per in zip(player_list, opponent_list, start_or_no_list, position_list, minute_list, \n",
    "                                    touches_list, pressures_list, xg_list, xa_list, sca_list ,gca_list, \n",
    "                                    shots_on_target_list, passes_pct_list, \n",
    "                                    carries_list, carry_progressive_distance_list, dribbles_list, dribbles_completed_list):\n",
    "            writer.writerow({\n",
    "                'player':player, 'opponent':opponent, 'start':start, 'position':position, 'minute':minute, \n",
    "                'touch':touch, 'pressure':pressure, 'xg':xg, 'xa':xa, 'sca':sca, 'gca':gca, 'sot':sot, 'pass_pct':pass_pct,\n",
    "                'carries':carry, 'prog_dis':prog_dis, 'dribble_attempt':dribble, 'dribble_suc':dribble_per\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
